---
spiders:

  # Retrieving links to the month pages
  archive:
    start_url: https://paris.demosphere.net/?selectStartTime=1172703601&endTime=1175378401&limit=1000&showArchiveLinks=1
    next:
      scraper:
        sel: '#archive > table td > a'
        fields:
          url:
            attr: href
            eval: value.replace('&limit=1000', '')
          spider:
            constant: month
    max_depth: 0

  # Retrieving full list of events per month
  month:
    next:
      scraper:
        iterator: .dcal > .day a[href^='/rv/']
        fields:
          url:
            attr: href
          spider:
            constant: rv
    max_depth: 1

  # Retrieving the actual events
  rv:
    scrapers:

      # Scraping events
      events:
        fields:
          title:
            sel: title
          url:
            sel: link[rel=canonical]
            attr: href
          date:
            sel: '#dateContents > .date'
            attr: data-val
          time:
            sel: '#dateContents > .time'
            attr: data-val
          themes:
            it: .topicsList > a
            join: '|'
          comments:
            sel: .actionBoxLinkText
            eval: "re.sub(r'[^0-9]', '', value)"
          parts:
            sel: '#textPart0 .textNav > a'
            eval: len(elements)
            default: 1
          address:
            sel: .address-text > a
            eval: "' § '.join([s.strip() for s in value.split('\\n')])"
          coordinates:
            sel: .mapimage-link
            attr: href
            eval: "value.split('place/')[-1].split('/')[0]"
          incomplete:
            sel: .incomplete
            constant: 1
          first:
            sel: .dayrank1
            constant: 1
          second:
            sel: .dayrank2
            constant: 1

      # Scraping comments
      comments:
        iterator: "#comments-list .comment"
        context:
          url:
            sel: link[rel=canonical]
            attr: href
        fields:
          url:
            get: url
          id:
            attr: id
            split: value.split('-')[-1]
          title:
            sel: .comment-title > a
          author:
            sel: .comment-information
            eval: "value.strip().rsplit(',', 1)[0].replace('Par ', '')"
          date:
            sel: .comment-information
            eval: "value.strip().split('le ')[-1].split(' à')[0]"
          time:
            sel: .comment-information
            eval: "value.strip().split('à ')[-1]"
          text:
            sel: .comment-body > p
            extract: outer_html

      # Scraping text
      paragraphs:
        iterator: .textPart
        context:
          url:
            sel: link[rel=canonical]
            attr: href
        fields:
          url:
            get: url
          title:
            sel: .openingBlock
          text:
            it: .openingBlock ~ p:not(.floatRight):not(.closingBlock)
            item:
              extract: text
              transform: strip
            join: '\n'
          links:
            it: .demosphere-source-link > a
            item: href
            join: '|'
          sources:
            it: .demosphere-sources > a
            item: href
            join: '|'
